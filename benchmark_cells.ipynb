{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "DLQZdhBISSkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MJh2brKMSYLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics tifffile"
      ],
      "metadata": {
        "id": "MmjwJf0rSfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENCV_LOG_LEVEL\"] = \"OFF\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms, models\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tifffile\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001 # Slightly higher LR is okay for Transfer Learning (Head only)\n",
        "EPOCHS = 15\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 2  # Binary: Dead vs Alive\n",
        "TRAIN_SPLIT = 0.7\n",
        "VAL_SPLIT = 0.15\n",
        "\n",
        "# Data transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(180),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "\n",
        "PATH_LIVE = \"/content/drive/MyDrive/Training_Images/291225 live Hela Cells\"\n",
        "PATH_DEAD = \"/content/drive/MyDrive/Training_Images/291225 Dead Hela Cells\"\n",
        "PATH_AGGR_1 = \"/content/drive/MyDrive/Training_Images/Clumps and debris R4 tiff\"\n",
        "PATH_AGGR_2 = \"/content/drive/MyDrive/Training_Images/R4 DPSC p11 Jan 30 _R4\"\n",
        "\n",
        "class CellDataset(Dataset):\n",
        "    def __init__(self, data_sources, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        self.valid_exts = ('.tif', '.tiff', '.png', '.jpg', '.jpeg', '.bmp')\n",
        "\n",
        "        print(f\"\\nScanning for images...\")\n",
        "        for folder_path, m_label, v_label in data_sources:\n",
        "            if not os.path.isdir(folder_path):\n",
        "                print(f\"ERROR: Folder not found: {folder_path}\")\n",
        "                continue\n",
        "\n",
        "            count = 0\n",
        "            for root, _, files in os.walk(folder_path):\n",
        "                for file in files:\n",
        "                    if file.lower().endswith(self.valid_exts):\n",
        "                        full_path = os.path.join(root, file)\n",
        "                        self.samples.append((full_path, m_label, v_label))\n",
        "                        count += 1\n",
        "            print(f\"Found {count} images in: {os.path.basename(folder_path)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, m_label, v_label = self.samples[idx]\n",
        "        final_image = None\n",
        "\n",
        "        # METHOD 1: OpenCV\n",
        "        try:\n",
        "            img_array = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "            if img_array is not None:\n",
        "                image_rgb = None\n",
        "                if len(img_array.shape) == 2:\n",
        "                    image_rgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
        "                elif len(img_array.shape) == 3:\n",
        "                    image_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                if image_rgb is not None:\n",
        "                    final_image = Image.fromarray(image_rgb)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # METHOD 2: Tifffile\n",
        "        if final_image is None:\n",
        "            try:\n",
        "                img_array = tifffile.imread(path)\n",
        "                if len(img_array.shape) == 3:\n",
        "                    img_array = img_array[0]\n",
        "                final_image = Image.fromarray(img_array).convert('RGB')\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # METHOD 3: Pillow\n",
        "        if final_image is None:\n",
        "            try:\n",
        "                final_image = Image.open(path).convert('RGB')\n",
        "            except Exception:\n",
        "                print(f\"Could not load: {os.path.basename(path)}\")\n",
        "                final_image = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        if self.transform:\n",
        "            final_image = self.transform(final_image)\n",
        "\n",
        "        target = v_label if v_label != -1 else 0\n",
        "        return final_image, target\n",
        "\n",
        "# Config: (Path, Morphology, Viability)\n",
        "data_config = [\n",
        "    (PATH_LIVE, 0, 1),\n",
        "    (PATH_DEAD, 0, 0),\n",
        "    (PATH_AGGR_1, 1, -1),\n",
        "    (PATH_AGGR_2, 1, -1)\n",
        "]\n",
        "\n",
        "full_dataset = CellDataset(data_config, transform=None)\n",
        "singlet_indices = [i for i, x in enumerate(full_dataset.samples) if x[2] != -1]\n",
        "singlet_dataset = torch.utils.data.Subset(full_dataset, singlet_indices)\n",
        "print(f\"Training on {len(singlet_dataset)} Singlet (Live/Dead) images.\")\n",
        "\n",
        "# Splits\n",
        "train_size = int(TRAIN_SPLIT * len(singlet_dataset))\n",
        "val_size = int(VAL_SPLIT * len(singlet_dataset))\n",
        "test_size = len(singlet_dataset) - train_size - val_size\n",
        "train_sub, val_sub, test_sub = random_split(singlet_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.subset[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "train_data = TransformSubset(train_sub, transform=train_transforms)\n",
        "val_data = TransformSubset(val_sub, transform=val_transforms)\n",
        "test_data = TransformSubset(test_sub, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ==========================================\n",
        "# 2. MODEL FACTORY (WITH FREEZING)\n",
        "# ==========================================\n",
        "\n",
        "# --- Custom SAM-Inspired Model (Trained from Scratch) ---\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        return self.sigmoid(avg_out + max_out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        return self.sigmoid(self.conv1(torch.cat([avg_out, max_out], dim=1)))\n",
        "\n",
        "class SAMInspiredCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SAMInspiredCNN, self).__init__()\n",
        "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.ca = ChannelAttention(128)\n",
        "        self.sa = SpatialAttention()\n",
        "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We don't freeze SAM model as it's \"Custom\"\n",
        "        return self.backbone(x)\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def create_model(model_name, num_classes=2):\n",
        "    print(f\"Creating model: {model_name}...\")\n",
        "    model = None\n",
        "    freeze = True # Default to Transfer Learning\n",
        "\n",
        "    if model_name == 'sam_cnn':\n",
        "        model = SAMInspiredCNN(num_classes=num_classes)\n",
        "        freeze = False # Custom model should be trained fully\n",
        "\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    elif model_name == 'vgg19':\n",
        "        model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet18':\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet34':\n",
        "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.fc.in_features if isinstance(model.fc, nn.Linear) else 512\n",
        "        model.fc = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.fc.in_features if isinstance(model.fc, nn.Linear) else 2048\n",
        "        model.fc = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'efficientnet_b0':\n",
        "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'efficientnet_b1':\n",
        "        model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'mobilenet_v2':\n",
        "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'vit_b_16':\n",
        "        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.heads.head.in_features if isinstance(model.heads.head, nn.Linear) else 768\n",
        "        model.heads.head = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'swin_t':\n",
        "        model = models.swin_t(weights=models.Swin_T_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.head.in_features if isinstance(model.head, nn.Linear) else 768\n",
        "        model.head = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: '{model_name}'. Choose from: vgg16, vgg19, resnet18, resnet34, resnet50, efficientnet_b0, efficientnet_b1, mobilenet_v2, vit_b_16, swin_t, sam_cnn\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def count_parameters(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total, trainable\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING & EVALUATION LOOP\n",
        "# ==========================================\n",
        "\n",
        "def train_and_evaluate(model_name, epochs=EPOCHS):\n",
        "    model = create_model(model_name, NUM_CLASSES).to(device)\n",
        "    total_params, trainable_params = count_parameters(model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Optimizer only updates parameters that require grad\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "    # Initialize Metrics\n",
        "    metric_acc = torchmetrics.Accuracy(task=\"binary\").to(device)\n",
        "    metric_prec = torchmetrics.Precision(task=\"binary\").to(device)\n",
        "    metric_rec = torchmetrics.Recall(task=\"binary\").to(device)\n",
        "    metric_f1 = torchmetrics.F1Score(task=\"binary\").to(device)\n",
        "    metric_auroc = torchmetrics.AUROC(task=\"binary\").to(device)\n",
        "    metric_confmat = torchmetrics.ConfusionMatrix(task=\"binary\", num_classes=2).to(device)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    best_metrics = {}\n",
        "\n",
        "    print(f\"\\nTraining {model_name} | Total Params: {total_params:,} | Trainable: {trainable_params:,}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0 # Manual counter to fix len() error\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Manual stats update\n",
        "            bs = inputs.size(0)\n",
        "            running_loss += loss.item() * bs\n",
        "            total_samples += bs\n",
        "\n",
        "        train_loss = running_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "        val_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                val_preds.append(preds)\n",
        "                val_targets.append(labels)\n",
        "                val_probs.append(probs)\n",
        "\n",
        "        if len(val_preds) > 0:\n",
        "            val_preds = torch.cat(val_preds)\n",
        "            val_targets = torch.cat(val_targets)\n",
        "            val_probs = torch.cat(val_probs)\n",
        "\n",
        "            acc = metric_acc(val_preds, val_targets).item() * 100\n",
        "            prec = metric_prec(val_preds, val_targets).item() * 100\n",
        "            rec = metric_rec(val_preds, val_targets).item() * 100\n",
        "            f1 = metric_f1(val_preds, val_targets).item() * 100\n",
        "            try:\n",
        "                auroc = metric_auroc(val_probs, val_targets).item() * 100\n",
        "            except:\n",
        "                auroc = 0.0\n",
        "        else:\n",
        "            acc, prec, rec, f1, auroc = 0,0,0,0,0\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Val F1: {f1:.2f}% | Val Acc: {acc:.2f}%\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            conf_matrix = metric_confmat(val_preds, val_targets).cpu().numpy()\n",
        "            best_metrics = {\n",
        "                \"Accuracy\": acc,\n",
        "                \"Precision\": prec,\n",
        "                \"Recall\": rec,\n",
        "                \"F1-Score\": f1,\n",
        "                \"AUROC\": auroc,\n",
        "                \"Confusion Matrix\": conf_matrix,\n",
        "                \"Params\": total_params,\n",
        "                \"Trainable\": trainable_params\n",
        "            }\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/Training_Images/best_{model_name}.pth')\n",
        "\n",
        "    return best_metrics\n",
        "\n",
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'resnet18'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "lM4l4nu-SidH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}