{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "DLQZdhBISSkU",
        "outputId": "b7726282-ba7b-43b1-fb43-5dede9f3092c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MJh2brKMSYLl",
        "outputId": "9a029b19-8b0c-47fa-aa6c-38a851041a5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics tifffile"
      ],
      "metadata": {
        "id": "MmjwJf0rSfCb",
        "outputId": "7fa29a22-da42-4297-80a8-3e32a9f8658c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (2026.2.16)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.10.0+cu128)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.24.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->torchmetrics) (1.3.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENCV_LOG_LEVEL\"] = \"OFF\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision import transforms, models\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tifffile\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001 # Slightly higher LR is okay for Transfer Learning (Head only)\n",
        "EPOCHS = 15\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 2  # Binary: Dead vs Alive\n",
        "TRAIN_SPLIT = 0.7\n",
        "VAL_SPLIT = 0.15\n",
        "\n",
        "# Data transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(180),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "\n",
        "PATH_LIVE = \"/content/drive/MyDrive/Training_Images/291225 live Hela Cells\"\n",
        "PATH_DEAD = \"/content/drive/MyDrive/Training_Images/291225 Dead Hela Cells\"\n",
        "PATH_AGGR_1 = \"/content/drive/MyDrive/Training_Images/Clumps and debris R4 tiff\"\n",
        "PATH_AGGR_2 = \"/content/drive/MyDrive/Training_Images/R4 DPSC p11 Jan 30 _R4\"\n",
        "\n",
        "class CellDataset(Dataset):\n",
        "    def __init__(self, data_sources, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        self.valid_exts = ('.tif', '.tiff', '.png', '.jpg', '.jpeg', '.bmp')\n",
        "\n",
        "        print(f\"\\nScanning for images...\")\n",
        "        for folder_path, m_label, v_label in data_sources:\n",
        "            if not os.path.isdir(folder_path):\n",
        "                print(f\"ERROR: Folder not found: {folder_path}\")\n",
        "                continue\n",
        "\n",
        "            count = 0\n",
        "            for root, _, files in os.walk(folder_path):\n",
        "                for file in files:\n",
        "                    if file.lower().endswith(self.valid_exts):\n",
        "                        full_path = os.path.join(root, file)\n",
        "                        self.samples.append((full_path, m_label, v_label))\n",
        "                        count += 1\n",
        "            print(f\"Found {count} images in: {os.path.basename(folder_path)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, m_label, v_label = self.samples[idx]\n",
        "        final_image = None\n",
        "\n",
        "        # METHOD 1: OpenCV\n",
        "        try:\n",
        "            img_array = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "            if img_array is not None:\n",
        "                image_rgb = None\n",
        "                if len(img_array.shape) == 2:\n",
        "                    image_rgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
        "                elif len(img_array.shape) == 3:\n",
        "                    image_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                if image_rgb is not None:\n",
        "                    final_image = Image.fromarray(image_rgb)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # METHOD 2: Tifffile\n",
        "        if final_image is None:\n",
        "            try:\n",
        "                img_array = tifffile.imread(path)\n",
        "                if len(img_array.shape) == 3:\n",
        "                    img_array = img_array[0]\n",
        "                final_image = Image.fromarray(img_array).convert('RGB')\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # METHOD 3: Pillow\n",
        "        if final_image is None:\n",
        "            try:\n",
        "                final_image = Image.open(path).convert('RGB')\n",
        "            except Exception:\n",
        "                print(f\"Could not load: {os.path.basename(path)}\")\n",
        "                final_image = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        if self.transform:\n",
        "            final_image = self.transform(final_image)\n",
        "\n",
        "        target = v_label if v_label != -1 else 0\n",
        "        return final_image, target\n",
        "\n",
        "# Config: (Path, Morphology, Viability)\n",
        "data_config = [\n",
        "    (PATH_LIVE, 0, 1),\n",
        "    (PATH_DEAD, 0, 0),\n",
        "    (PATH_AGGR_1, 1, -1),\n",
        "    (PATH_AGGR_2, 1, -1)\n",
        "]\n",
        "\n",
        "full_dataset = CellDataset(data_config, transform=None)\n",
        "singlet_indices = [i for i, x in enumerate(full_dataset.samples) if x[2] != -1]\n",
        "singlet_dataset = torch.utils.data.Subset(full_dataset, singlet_indices)\n",
        "print(f\"Training on {len(singlet_dataset)} Singlet (Live/Dead) images.\")\n",
        "\n",
        "# Splits\n",
        "train_size = int(TRAIN_SPLIT * len(singlet_dataset))\n",
        "val_size = int(VAL_SPLIT * len(singlet_dataset))\n",
        "test_size = len(singlet_dataset) - train_size - val_size\n",
        "train_sub, val_sub, test_sub = random_split(singlet_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.subset[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "train_data = TransformSubset(train_sub, transform=train_transforms)\n",
        "val_data = TransformSubset(val_sub, transform=val_transforms)\n",
        "test_data = TransformSubset(test_sub, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# ==========================================\n",
        "# 2. MODEL FACTORY (WITH FREEZING)\n",
        "# ==========================================\n",
        "\n",
        "# --- Custom SAM-Inspired Model (Trained from Scratch) ---\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        return self.sigmoid(avg_out + max_out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        return self.sigmoid(self.conv1(torch.cat([avg_out, max_out], dim=1)))\n",
        "\n",
        "class SAMInspiredCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SAMInspiredCNN, self).__init__()\n",
        "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.ca = ChannelAttention(128)\n",
        "        self.sa = SpatialAttention()\n",
        "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We don't freeze SAM model as it's \"Custom\"\n",
        "        return self.backbone(x)\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def create_model(model_name, num_classes=2):\n",
        "    print(f\"Creating model: {model_name}...\")\n",
        "    model = None\n",
        "    freeze = True # Default to Transfer Learning\n",
        "\n",
        "    if model_name == 'sam_cnn':\n",
        "        model = SAMInspiredCNN(num_classes=num_classes)\n",
        "        freeze = False # Custom model should be trained fully\n",
        "\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    elif model_name == 'vgg19':\n",
        "        model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet18':\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet34':\n",
        "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.fc.in_features if isinstance(model.fc, nn.Linear) else 512\n",
        "        model.fc = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.fc.in_features if isinstance(model.fc, nn.Linear) else 2048\n",
        "        model.fc = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'efficientnet_b0':\n",
        "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'efficientnet_b1':\n",
        "        model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'mobilenet_v2':\n",
        "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.classifier[1].in_features if isinstance(model.classifier[1], nn.Linear) else 1280\n",
        "        model.classifier[1] = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'vit_b_16':\n",
        "        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.heads.head.in_features if isinstance(model.heads.head, nn.Linear) else 768\n",
        "        model.heads.head = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == 'swin_t':\n",
        "        model = models.swin_t(weights=models.Swin_T_Weights.DEFAULT)\n",
        "        set_parameter_requires_grad(model, freeze)\n",
        "        in_ftrs = model.head.in_features if isinstance(model.head, nn.Linear) else 768\n",
        "        model.head = nn.Linear(in_ftrs, num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: '{model_name}'. Choose from: vgg16, vgg19, resnet18, resnet34, resnet50, efficientnet_b0, efficientnet_b1, mobilenet_v2, vit_b_16, swin_t, sam_cnn\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def count_parameters(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total, trainable\n",
        "\n",
        "# ==========================================\n",
        "# 3. TRAINING & EVALUATION LOOP\n",
        "# ==========================================\n",
        "\n",
        "def train_and_evaluate(model_name, epochs=EPOCHS):\n",
        "    model = create_model(model_name, NUM_CLASSES).to(device)\n",
        "    total_params, trainable_params = count_parameters(model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Optimizer only updates parameters that require grad\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "    # Initialize Metrics\n",
        "    metric_acc = torchmetrics.Accuracy(task=\"binary\").to(device)\n",
        "    metric_prec = torchmetrics.Precision(task=\"binary\").to(device)\n",
        "    metric_rec = torchmetrics.Recall(task=\"binary\").to(device)\n",
        "    metric_f1 = torchmetrics.F1Score(task=\"binary\").to(device)\n",
        "    metric_auroc = torchmetrics.AUROC(task=\"binary\").to(device)\n",
        "    metric_confmat = torchmetrics.ConfusionMatrix(task=\"binary\", num_classes=2).to(device)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    best_metrics = {}\n",
        "\n",
        "    print(f\"\\nTraining {model_name} | Total Params: {total_params:,} | Trainable: {trainable_params:,}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0 # Manual counter to fix len() error\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Manual stats update\n",
        "            bs = inputs.size(0)\n",
        "            running_loss += loss.item() * bs\n",
        "            total_samples += bs\n",
        "\n",
        "        train_loss = running_loss / total_samples if total_samples > 0 else 0\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "        val_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                probs = torch.softmax(outputs, dim=1)[:, 1]\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                val_preds.append(preds)\n",
        "                val_targets.append(labels)\n",
        "                val_probs.append(probs)\n",
        "\n",
        "        if len(val_preds) > 0:\n",
        "            val_preds = torch.cat(val_preds)\n",
        "            val_targets = torch.cat(val_targets)\n",
        "            val_probs = torch.cat(val_probs)\n",
        "\n",
        "            acc = metric_acc(val_preds, val_targets).item() * 100\n",
        "            prec = metric_prec(val_preds, val_targets).item() * 100\n",
        "            rec = metric_rec(val_preds, val_targets).item() * 100\n",
        "            f1 = metric_f1(val_preds, val_targets).item() * 100\n",
        "            try:\n",
        "                auroc = metric_auroc(val_probs, val_targets).item() * 100\n",
        "            except:\n",
        "                auroc = 0.0\n",
        "        else:\n",
        "            acc, prec, rec, f1, auroc = 0,0,0,0,0\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Val F1: {f1:.2f}% | Val Acc: {acc:.2f}%\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            conf_matrix = metric_confmat(val_preds, val_targets).cpu().numpy()\n",
        "            best_metrics = {\n",
        "                \"Accuracy\": acc,\n",
        "                \"Precision\": prec,\n",
        "                \"Recall\": rec,\n",
        "                \"F1-Score\": f1,\n",
        "                \"AUROC\": auroc,\n",
        "                \"Confusion Matrix\": conf_matrix,\n",
        "                \"Params\": total_params,\n",
        "                \"Trainable\": trainable_params\n",
        "            }\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/Training_Images/best_{model_name}.pth')\n",
        "\n",
        "    return best_metrics"
      ],
      "metadata": {
        "id": "lM4l4nu-SidH",
        "outputId": "f4851522-a422-482e-8c02-80e356b51be2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Scanning for images...\n",
            "Found 1814 images in: 291225 live Hela Cells\n",
            "Found 1400 images in: 291225 Dead Hela Cells\n",
            "Found 1143 images in: Clumps and debris R4 tiff\n",
            "Found 2412 images in: R4 DPSC p11 Jan 30 _R4\n",
            "Training on 3214 Singlet (Live/Dead) images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'vgg16'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "vkqiorXaJSCT",
        "outputId": "d5b5cef2-4a30-4e35-b698-1a57c4b46c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vgg16...\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:02<00:00, 193MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training vgg16 | Total Params: 134,268,738 | Trainable: 8,194\n",
            "Epoch 1/15 | Loss: 0.6358 | Val F1: 61.80% | Val Acc: 67.43%\n",
            "Epoch 2/15 | Loss: 0.5695 | Val F1: 59.75% | Val Acc: 66.18%\n",
            "Epoch 3/15 | Loss: 0.5578 | Val F1: 61.15% | Val Acc: 67.84%\n",
            "Epoch 4/15 | Loss: 0.5575 | Val F1: 56.77% | Val Acc: 65.56%\n",
            "Epoch 5/15 | Loss: 0.5831 | Val F1: 82.70% | Val Acc: 81.95%\n",
            "Epoch 6/15 | Loss: 0.5774 | Val F1: 63.48% | Val Acc: 69.92%\n",
            "Epoch 7/15 | Loss: 0.5577 | Val F1: 89.48% | Val Acc: 88.59%\n",
            "Epoch 8/15 | Loss: 0.5929 | Val F1: 86.51% | Val Acc: 84.02%\n",
            "Epoch 9/15 | Loss: 0.5787 | Val F1: 85.55% | Val Acc: 84.23%\n",
            "Epoch 10/15 | Loss: 0.6026 | Val F1: 51.91% | Val Acc: 63.49%\n",
            "Epoch 11/15 | Loss: 0.5794 | Val F1: 78.04% | Val Acc: 78.63%\n",
            "Epoch 12/15 | Loss: 0.5608 | Val F1: 82.37% | Val Acc: 77.80%\n",
            "Epoch 13/15 | Loss: 0.5860 | Val F1: 85.36% | Val Acc: 82.78%\n",
            "Epoch 14/15 | Loss: 0.6020 | Val F1: 65.54% | Val Acc: 70.33%\n",
            "Epoch 15/15 | Loss: 0.5794 | Val F1: 67.47% | Val Acc: 71.99%\n",
            "\n",
            "==========================================================================================\n",
            "MODEL                | PARAMS (M) | ACC     | PREC    | REC     | F1      | AUROC  \n",
            "==========================================================================================\n",
            "vgg16                | 134.3      | 88.59   | 91.41   | 87.64   | 89.48   | 94.50  \n",
            "\n",
            "Detailed Confusion Matrices:\n",
            "\n",
            "--- vgg16 ---\n",
            "[[193  22]\n",
            " [ 33 234]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'vgg19'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "V5wuebnW0iqR",
        "outputId": "adfcb07c-ee51-43a6-f0df-a780267cb362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vgg19...\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548M/548M [00:10<00:00, 54.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training vgg19 | Total Params: 139,578,434 | Trainable: 8,194\n",
            "Epoch 1/15 | Loss: 0.5904 | Val F1: 69.78% | Val Acc: 71.78%\n",
            "Epoch 2/15 | Loss: 0.5441 | Val F1: 82.18% | Val Acc: 76.97%\n",
            "Epoch 3/15 | Loss: 0.5326 | Val F1: 59.28% | Val Acc: 67.22%\n",
            "Epoch 4/15 | Loss: 0.5410 | Val F1: 64.36% | Val Acc: 70.12%\n",
            "Epoch 5/15 | Loss: 0.5200 | Val F1: 41.54% | Val Acc: 59.13%\n",
            "Epoch 6/15 | Loss: 0.5841 | Val F1: 83.73% | Val Acc: 82.99%\n",
            "Epoch 7/15 | Loss: 0.5551 | Val F1: 79.92% | Val Acc: 80.29%\n",
            "Epoch 8/15 | Loss: 0.5680 | Val F1: 84.41% | Val Acc: 81.54%\n",
            "Epoch 9/15 | Loss: 0.5756 | Val F1: 84.85% | Val Acc: 82.37%\n",
            "Epoch 10/15 | Loss: 0.5662 | Val F1: 83.80% | Val Acc: 79.46%\n",
            "Epoch 11/15 | Loss: 0.6160 | Val F1: 83.58% | Val Acc: 83.61%\n",
            "Epoch 12/15 | Loss: 0.5514 | Val F1: 84.47% | Val Acc: 82.99%\n",
            "Epoch 13/15 | Loss: 0.5563 | Val F1: 85.11% | Val Acc: 83.82%\n",
            "Epoch 14/15 | Loss: 0.5685 | Val F1: 82.11% | Val Acc: 81.74%\n",
            "Epoch 15/15 | Loss: 0.5830 | Val F1: 62.66% | Val Acc: 69.09%\n",
            "\n",
            "==========================================================================================\n",
            "MODEL                | PARAMS (M) | ACC     | PREC    | REC     | F1      | AUROC  \n",
            "==========================================================================================\n",
            "vgg19                | 139.6      | 83.82   | 86.77   | 83.52   | 85.11   | 91.90  \n",
            "\n",
            "Detailed Confusion Matrices:\n",
            "\n",
            "--- vgg19 ---\n",
            "[[181  34]\n",
            " [ 44 223]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'resnet18'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "r6lGaCdF0rh7",
        "outputId": "40a6618b-b496-461e-a8d7-0cf3e18053c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: resnet18...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet18 | Total Params: 11,177,538 | Trainable: 1,026\n",
            "Epoch 1/15 | Loss: 0.5653 | Val F1: 66.50% | Val Acc: 72.20%\n",
            "Epoch 2/15 | Loss: 0.4361 | Val F1: 12.63% | Val Acc: 48.34%\n",
            "Epoch 3/15 | Loss: 0.4046 | Val F1: 50.84% | Val Acc: 63.49%\n",
            "Epoch 4/15 | Loss: 0.3915 | Val F1: 13.94% | Val Acc: 48.76%\n",
            "Epoch 5/15 | Loss: 0.3754 | Val F1: 24.34% | Val Acc: 52.28%\n",
            "Epoch 6/15 | Loss: 0.3784 | Val F1: 22.00% | Val Acc: 51.45%\n",
            "Epoch 7/15 | Loss: 0.3379 | Val F1: 39.64% | Val Acc: 58.30%\n",
            "Epoch 8/15 | Loss: 0.3365 | Val F1: 58.36% | Val Acc: 67.43%\n",
            "Epoch 9/15 | Loss: 0.3269 | Val F1: 41.07% | Val Acc: 58.92%\n",
            "Epoch 10/15 | Loss: 0.3376 | Val F1: 56.45% | Val Acc: 66.39%\n",
            "Epoch 11/15 | Loss: 0.3438 | Val F1: 42.94% | Val Acc: 59.75%\n",
            "Epoch 12/15 | Loss: 0.3475 | Val F1: 42.94% | Val Acc: 59.75%\n",
            "Epoch 13/15 | Loss: 0.3283 | Val F1: 61.14% | Val Acc: 68.88%\n",
            "Epoch 14/15 | Loss: 0.3570 | Val F1: 19.59% | Val Acc: 50.62%\n",
            "Epoch 15/15 | Loss: 0.3458 | Val F1: 26.06% | Val Acc: 52.90%\n",
            "\n",
            "==========================================================================================\n",
            "MODEL                | PARAMS (M) | ACC     | PREC    | REC     | F1      | AUROC  \n",
            "==========================================================================================\n",
            "resnet18             | 11.2       | 72.20   | 100.00  | 49.81   | 66.50   | 94.33  \n",
            "\n",
            "Detailed Confusion Matrices:\n",
            "\n",
            "--- resnet18 ---\n",
            "[[215   0]\n",
            " [134 133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'resnet34'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "rqiZs1mt0vlq",
        "outputId": "79a2b854-21da-4a31-fc1f-b3cb2db07e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: resnet34...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet34 | Total Params: 21,285,698 | Trainable: 1,026\n",
            "Epoch 1/15 | Loss: 0.6104 | Val F1: 79.22% | Val Acc: 80.08%\n",
            "Epoch 2/15 | Loss: 0.4653 | Val F1: 42.48% | Val Acc: 59.54%\n",
            "Epoch 3/15 | Loss: 0.4438 | Val F1: 74.02% | Val Acc: 76.56%\n",
            "Epoch 4/15 | Loss: 0.4374 | Val F1: 87.79% | Val Acc: 86.72%\n",
            "Epoch 5/15 | Loss: 0.4215 | Val F1: 24.92% | Val Acc: 52.49%\n",
            "Epoch 6/15 | Loss: 0.3971 | Val F1: 89.51% | Val Acc: 88.38%\n",
            "Epoch 7/15 | Loss: 0.3983 | Val F1: 88.57% | Val Acc: 86.72%\n",
            "Epoch 8/15 | Loss: 0.3912 | Val F1: 85.25% | Val Acc: 84.85%\n",
            "Epoch 9/15 | Loss: 0.3787 | Val F1: 68.47% | Val Acc: 73.44%\n",
            "Epoch 10/15 | Loss: 0.3848 | Val F1: 86.82% | Val Acc: 86.51%\n",
            "Epoch 11/15 | Loss: 0.3659 | Val F1: 89.23% | Val Acc: 88.38%\n",
            "Epoch 12/15 | Loss: 0.3759 | Val F1: 82.23% | Val Acc: 82.78%\n",
            "Epoch 13/15 | Loss: 0.3805 | Val F1: 84.08% | Val Acc: 84.44%\n",
            "Epoch 14/15 | Loss: 0.4185 | Val F1: 52.89% | Val Acc: 64.52%\n",
            "Epoch 15/15 | Loss: 0.3906 | Val F1: 89.61% | Val Acc: 87.97%\n",
            "\n",
            "==========================================================================================\n",
            "MODEL                | PARAMS (M) | ACC     | PREC    | REC     | F1      | AUROC  \n",
            "==========================================================================================\n",
            "resnet34             | 21.3       | 87.97   | 85.91   | 93.63   | 89.61   | 95.29  \n",
            "\n",
            "Detailed Confusion Matrices:\n",
            "\n",
            "--- resnet34 ---\n",
            "[[174  41]\n",
            " [ 17 250]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'resnet50'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "b03BzfDX0xr_",
        "outputId": "3d4f55c8-4bbf-4999-a9af-2c3d4068eb88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: resnet50...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet50 | Total Params: 23,512,130 | Trainable: 4,098\n",
            "Epoch 1/15 | Loss: 0.5739 | Val F1: 77.74% | Val Acc: 68.88%\n",
            "Epoch 2/15 | Loss: 0.4969 | Val F1: 91.92% | Val Acc: 91.29%\n",
            "Epoch 3/15 | Loss: 0.4570 | Val F1: 87.10% | Val Acc: 86.72%\n",
            "Epoch 4/15 | Loss: 0.4381 | Val F1: 84.08% | Val Acc: 80.91%\n",
            "Epoch 5/15 | Loss: 0.4315 | Val F1: 89.59% | Val Acc: 87.76%\n",
            "Epoch 6/15 | Loss: 0.3948 | Val F1: 87.26% | Val Acc: 86.31%\n",
            "Epoch 7/15 | Loss: 0.4095 | Val F1: 85.38% | Val Acc: 84.44%\n",
            "Epoch 8/15 | Loss: 0.3851 | Val F1: 87.57% | Val Acc: 85.27%\n",
            "Epoch 9/15 | Loss: 0.4133 | Val F1: 86.88% | Val Acc: 85.27%\n",
            "Epoch 10/15 | Loss: 0.3827 | Val F1: 84.84% | Val Acc: 83.61%\n",
            "Epoch 11/15 | Loss: 0.3601 | Val F1: 89.32% | Val Acc: 88.59%\n",
            "Epoch 12/15 | Loss: 0.3687 | Val F1: 85.93% | Val Acc: 84.23%\n",
            "Epoch 13/15 | Loss: 0.3853 | Val F1: 83.83% | Val Acc: 80.71%\n",
            "Epoch 14/15 | Loss: 0.3553 | Val F1: 84.14% | Val Acc: 80.91%\n",
            "Epoch 15/15 | Loss: 0.3701 | Val F1: 84.19% | Val Acc: 80.91%\n",
            "\n",
            "==========================================================================================\n",
            "MODEL                | PARAMS (M) | ACC     | PREC    | REC     | F1      | AUROC  \n",
            "==========================================================================================\n",
            "resnet50             | 23.5       | 91.29   | 94.47   | 89.51   | 91.92   | 96.48  \n",
            "\n",
            "Detailed Confusion Matrices:\n",
            "\n",
            "--- resnet50 ---\n",
            "[[201  14]\n",
            " [ 28 239]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'efficientnet_b0'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "Q6fJuLqM04F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'efficientnet_b1'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "aBNynsrf1AEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'mobilenet_v2'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "PZEJ1qzU1EwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'vit_b_16'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "LiD2jnuK1L5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'swin_t'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "Jv1JBT5a1OyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mKQNXl_1SoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. RUN BENCHMARK\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    models_to_run = [\n",
        "        'sam_cnn'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for m in models_to_run:\n",
        "        try:\n",
        "            metrics = train_and_evaluate(m, epochs=EPOCHS)\n",
        "            results[m] = metrics\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to run {m}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{'MODEL':<20} | {'PARAMS (M)':<10} | {'ACC':<7} | {'PREC':<7} | {'REC':<7} | {'F1':<7} | {'AUROC':<7}\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            params_m = metrics['Params'] / 1e6\n",
        "            print(f\"{m:<20} | {params_m:<10.1f} | {metrics['Accuracy']:<7.2f} | {metrics['Precision']:<7.2f} | {metrics['Recall']:<7.2f} | {metrics['F1-Score']:<7.2f} | {metrics['AUROC']:<7.2f}\")\n",
        "\n",
        "    print(\"\\nDetailed Confusion Matrices:\")\n",
        "    for m, metrics in results.items():\n",
        "        if metrics:\n",
        "            print(f\"\\n--- {m} ---\")\n",
        "            print(metrics['Confusion Matrix'])"
      ],
      "metadata": {
        "id": "uRFhp1Zn1VAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}